{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b1bef12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:17:59.312131Z",
     "iopub.status.busy": "2025-05-22T17:17:59.311868Z",
     "iopub.status.idle": "2025-05-22T17:18:05.553723Z",
     "shell.execute_reply": "2025-05-22T17:18:05.553129Z"
    },
    "papermill": {
     "duration": 6.248829,
     "end_time": "2025-05-22T17:18:05.555192",
     "exception": false,
     "start_time": "2025-05-22T17:17:59.306363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers.configuration_utils import PretrainedConfig\n",
    "# from transformers.modeling_rope_utils import rope_config_validation\n",
    "from transformers.utils import logging\n",
    "\n",
    "\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "\n",
    "class Qwen2Config(PretrainedConfig):\n",
    "    \n",
    "\n",
    "    model_type = \"qwen2\"\n",
    "    keys_to_ignore_at_inference = [\"past_key_values\"]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size=151936,\n",
    "        hidden_size=896,\n",
    "        intermediate_size=4864,\n",
    "        num_hidden_layers=24,\n",
    "        num_attention_heads=14,\n",
    "        num_key_value_heads=2,\n",
    "        hidden_act=\"silu\",\n",
    "        max_position_embeddings=32768,\n",
    "        initializer_range=0.02,\n",
    "        rms_norm_eps=1e-6,\n",
    "        use_cache=True,\n",
    "        tie_word_embeddings=True,\n",
    "        rope_theta=1000000.0,\n",
    "        rope_scaling=None,\n",
    "        use_sliding_window=False,\n",
    "        sliding_window= 32768,\n",
    "        max_window_layers=24,\n",
    "        attention_dropout=0.0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.hidden_size = hidden_size\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.use_sliding_window = use_sliding_window\n",
    "        self.sliding_window = sliding_window  # we check `use_sliding_window` in the modeling code\n",
    "        self.max_window_layers = max_window_layers\n",
    "\n",
    "        # for backward compatibility\n",
    "        if num_key_value_heads is None:\n",
    "            num_key_value_heads = num_attention_heads\n",
    "\n",
    "        self.num_key_value_heads = num_key_value_heads\n",
    "        self.hidden_act = hidden_act\n",
    "        self.initializer_range = initializer_range\n",
    "        self.rms_norm_eps = rms_norm_eps\n",
    "        self.use_cache = use_cache\n",
    "        self.rope_theta = rope_theta\n",
    "        self.rope_scaling = rope_scaling\n",
    "        self.attention_dropout = attention_dropout\n",
    "\n",
    "        super().__init__(\n",
    "            tie_word_embeddings=tie_word_embeddings,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a4806f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:18:05.563497Z",
     "iopub.status.busy": "2025-05-22T17:18:05.563168Z",
     "iopub.status.idle": "2025-05-22T17:18:31.836285Z",
     "shell.execute_reply": "2025-05-22T17:18:31.835665Z"
    },
    "papermill": {
     "duration": 26.27862,
     "end_time": "2025-05-22T17:18:31.837689",
     "exception": false,
     "start_time": "2025-05-22T17:18:05.559069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 17:18:16.070657: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747934296.311638      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747934296.381379      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers.generation import GenerationMixin\n",
    "import inspect\n",
    "import math\n",
    "import warnings\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "\n",
    "from transformers.activations import ACT2FN\n",
    "from transformers.cache_utils import Cache, DynamicCache, StaticCache\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "from transformers.utils import (\n",
    "    logging,\n",
    "   \n",
    ")\n",
    "# from transformers.modeling_layers import GradientCheckpointingLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a63ac5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:18:31.846056Z",
     "iopub.status.busy": "2025-05-22T17:18:31.845554Z",
     "iopub.status.idle": "2025-05-22T17:18:31.849398Z",
     "shell.execute_reply": "2025-05-22T17:18:31.848876Z"
    },
    "papermill": {
     "duration": 0.009002,
     "end_time": "2025-05-22T17:18:31.850484",
     "exception": false,
     "start_time": "2025-05-22T17:18:31.841482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "\n",
    "_CHECKPOINT_FOR_DOC = \"Qwen/Qwen2-7B-beta\"\n",
    "_CONFIG_FOR_DOC = \"Qwen2Config\"\n",
    "\n",
    "QWEN2_PRETRAINED_MODEL_ARCHIVE_LIST = [\n",
    "    \"Qwen/Qwen2-7B-beta\",\n",
    "    # See all Qwen2 models at https://huggingface.co/models?filter=qwen2\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb78cb5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:18:31.858681Z",
     "iopub.status.busy": "2025-05-22T17:18:31.858475Z",
     "iopub.status.idle": "2025-05-22T17:18:31.909305Z",
     "shell.execute_reply": "2025-05-22T17:18:31.908706Z"
    },
    "papermill": {
     "duration": 0.056707,
     "end_time": "2025-05-22T17:18:31.910601",
     "exception": false,
     "start_time": "2025-05-22T17:18:31.853894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Qwen2MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.intermediate_size = config.intermediate_size\n",
    "        self.gate_proj = nn.Linear(self.hidden_size, self.intermediate_size, bias=False)\n",
    "        self.up_proj = nn.Linear(self.hidden_size, self.intermediate_size, bias=False)\n",
    "        self.down_proj = nn.Linear(self.intermediate_size, self.hidden_size, bias=False)\n",
    "        self.act_fn = ACT2FN[config.hidden_act]\n",
    "\n",
    "    def forward(self, x):\n",
    "        down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
    "        return down_proj\n",
    "\n",
    "\n",
    "def rotate_half(x):\n",
    "    \"\"\"Rotates half the hidden dims of the input.\"\"\"\n",
    "    x1 = x[..., : x.shape[-1] // 2]\n",
    "    x2 = x[..., x.shape[-1] // 2 :]\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "\n",
    "def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
    "    \"\"\"Applies Rotary Position Embedding to the query and key tensors.\n",
    "\n",
    "    Args:\n",
    "        q (`torch.Tensor`): The query tensor.\n",
    "        k (`torch.Tensor`): The key tensor.\n",
    "        cos (`torch.Tensor`): The cosine part of the rotary embedding.\n",
    "        sin (`torch.Tensor`): The sine part of the rotary embedding.\n",
    "        position_ids (`torch.Tensor`, *optional*):\n",
    "            Deprecated and unused.\n",
    "        unsqueeze_dim (`int`, *optional*, defaults to 1):\n",
    "            The 'unsqueeze_dim' argument specifies the dimension along which to unsqueeze cos[position_ids] and\n",
    "            sin[position_ids] so that they can be properly broadcasted to the dimensions of q and k. For example, note\n",
    "            that cos[position_ids] and sin[position_ids] have the shape [batch_size, seq_len, head_dim]. Then, if q and\n",
    "            k have the shape [batch_size, heads, seq_len, head_dim], then setting unsqueeze_dim=1 makes\n",
    "            cos[position_ids] and sin[position_ids] broadcastable to the shapes of q and k. Similarly, if q and k have\n",
    "            the shape [batch_size, seq_len, heads, head_dim], then set unsqueeze_dim=2.\n",
    "    Returns:\n",
    "        `tuple(torch.Tensor)` comprising of the query and key tensors rotated using the Rotary Position Embedding.\n",
    "    \"\"\"\n",
    "    cos = cos.unsqueeze(unsqueeze_dim)\n",
    "    sin = sin.unsqueeze(unsqueeze_dim)\n",
    "    q_embed = (q * cos) + (rotate_half(q) * sin)\n",
    "    k_embed = (k * cos) + (rotate_half(k) * sin)\n",
    "    return q_embed, k_embed\n",
    "\n",
    "\n",
    "def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    This is the equivalent of torch.repeat_interleave(x, dim=1, repeats=n_rep). The hidden states go from (batch,\n",
    "    num_key_value_heads, seqlen, head_dim) to (batch, num_attention_heads, seqlen, head_dim)\n",
    "    \"\"\"\n",
    "    batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
    "    if n_rep == 1:\n",
    "        return hidden_states\n",
    "    hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
    "    return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
    "\n",
    "\n",
    "def eager_attention_forward(\n",
    "    module: nn.Module,\n",
    "    query: torch.Tensor,\n",
    "    key: torch.Tensor,\n",
    "    value: torch.Tensor,\n",
    "    attention_mask: Optional[torch.Tensor],\n",
    "    scaling: float,\n",
    "    dropout: float = 0.0,\n",
    "    **kwargs,\n",
    "):\n",
    "    key_states = repeat_kv(key, module.num_key_value_groups)\n",
    "    value_states = repeat_kv(value, module.num_key_value_groups)\n",
    "\n",
    "    attn_weights = torch.matmul(query, key_states.transpose(2, 3)) * scaling\n",
    "    if attention_mask is not None:\n",
    "        causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]\n",
    "        attn_weights = attn_weights + causal_mask\n",
    "\n",
    "    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query.dtype)\n",
    "    attn_weights = nn.functional.dropout(attn_weights, p=dropout, training=module.training)\n",
    "    attn_output = torch.matmul(attn_weights, value_states)\n",
    "    attn_output = attn_output.transpose(1, 2).contiguous()\n",
    "\n",
    "    return attn_output, attn_weights\n",
    "\n",
    "\n",
    "class Qwen2Attention(nn.Module):\n",
    "    \"\"\"Multi-headed attention from 'Attention Is All You Need' paper\"\"\"\n",
    "\n",
    "    def __init__(self, config: Qwen2Config, layer_idx: int):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.layer_idx = layer_idx\n",
    "        self.head_dim = getattr(config, \"head_dim\", config.hidden_size // config.num_attention_heads)\n",
    "        self.num_key_value_groups = config.num_attention_heads // config.num_key_value_heads\n",
    "        self.scaling = self.head_dim**-0.5\n",
    "        self.attention_dropout = config.attention_dropout\n",
    "        self.is_causal = True\n",
    "        self.q_proj = nn.Linear(config.hidden_size, config.num_attention_heads * self.head_dim, bias=True)\n",
    "        self.k_proj = nn.Linear(config.hidden_size, config.num_key_value_heads * self.head_dim, bias=True)\n",
    "        self.v_proj = nn.Linear(config.hidden_size, config.num_key_value_heads * self.head_dim, bias=True)\n",
    "        self.o_proj = nn.Linear(config.num_attention_heads * self.head_dim, config.hidden_size, bias=False)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        position_embeddings: Tuple[torch.Tensor, torch.Tensor],\n",
    "        attention_mask: Optional[torch.Tensor],\n",
    "        past_key_value: Optional[Cache] = None,\n",
    "        cache_position: Optional[torch.LongTensor] = None,\n",
    "        **kwargs\n",
    "    ) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]:\n",
    "        input_shape = hidden_states.shape[:-1]\n",
    "        hidden_shape = (*input_shape, -1, self.head_dim)\n",
    "\n",
    "        query_states = self.q_proj(hidden_states).view(hidden_shape).transpose(1, 2)\n",
    "        key_states = self.k_proj(hidden_states).view(hidden_shape).transpose(1, 2)\n",
    "        value_states = self.v_proj(hidden_states).view(hidden_shape).transpose(1, 2)\n",
    "\n",
    "        cos, sin = position_embeddings\n",
    "        query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
    "\n",
    "        if past_key_value is not None:\n",
    "            # sin and cos are specific to RoPE models; cache_position needed for the static cache\n",
    "            cache_kwargs = {\"sin\": sin, \"cos\": cos, \"cache_position\": cache_position}\n",
    "            key_states, value_states = past_key_value.update(key_states, value_states, self.layer_idx, cache_kwargs)\n",
    "\n",
    "       \n",
    "\n",
    "        attention_interface: Callable = eager_attention_forward\n",
    "     \n",
    "\n",
    "        attn_output, attn_weights = attention_interface(\n",
    "            self,\n",
    "            query_states,\n",
    "            key_states,\n",
    "            value_states,\n",
    "            attention_mask,\n",
    "            dropout=0.0 if not self.training else self.attention_dropout,\n",
    "            scaling=self.scaling,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        attn_output = attn_output.reshape(*input_shape, -1).contiguous()\n",
    "        attn_output = self.o_proj(attn_output)\n",
    "        return attn_output, attn_weights\n",
    "\n",
    "\n",
    "\n",
    "class Qwen2RMSNorm(nn.Module):\n",
    "    def __init__(self, hidden_size, eps=1e-6):\n",
    "        \"\"\"\n",
    "        Qwen2RMSNorm is equivalent to T5LayerNorm\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.variance_epsilon = eps\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        input_dtype = hidden_states.dtype\n",
    "        hidden_states = hidden_states.to(torch.float32)\n",
    "        variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
    "        hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
    "        return self.weight * hidden_states.to(input_dtype)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f\"{tuple(self.weight.shape)}, eps={self.variance_epsilon}\"\n",
    "\n",
    "\n",
    "class Qwen2DecoderLayer(nn.Module):\n",
    "    def __init__(self, config: Qwen2Config, layer_idx: int):\n",
    "        super().__init__()\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.self_attn = Qwen2Attention(config=config, layer_idx=layer_idx)\n",
    "        self.mlp = Qwen2MLP(config)\n",
    "        self.input_layernorm = Qwen2RMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n",
    "        self.post_attention_layernorm = Qwen2RMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n",
    "        \n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_value: Optional[Cache] = None,\n",
    "        # output_attentions: Optional[bool] = False,\n",
    "        use_cache: Optional[bool] = False,\n",
    "        cache_position: Optional[torch.LongTensor] = None,\n",
    "        position_embeddings: Optional[Tuple[torch.Tensor, torch.Tensor]] = None,  # necessary, but kept here for BC\n",
    "        **kwargs,\n",
    "    ) -> Tuple[torch.FloatTensor, Optional[Tuple[torch.FloatTensor, torch.FloatTensor]]]:\n",
    "        residual = hidden_states\n",
    "        hidden_states = self.input_layernorm(hidden_states)\n",
    "\n",
    "        # Self Attention\n",
    "        hidden_states, self_attn_weights = self.self_attn(\n",
    "            hidden_states=hidden_states,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            past_key_value=past_key_value,\n",
    "            use_cache=use_cache,\n",
    "            cache_position=cache_position,\n",
    "            position_embeddings=position_embeddings,\n",
    "            **kwargs,\n",
    "        )\n",
    "        hidden_states = residual + hidden_states\n",
    "\n",
    "        # Fully Connected\n",
    "        residual = hidden_states\n",
    "        hidden_states = self.post_attention_layernorm(hidden_states)\n",
    "        hidden_states = self.mlp(hidden_states)\n",
    "        hidden_states = residual + hidden_states\n",
    "\n",
    "        outputs = (hidden_states,)\n",
    "        \n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "\n",
    "class Qwen2PreTrainedModel(PreTrainedModel):\n",
    "    config_class = Qwen2Config\n",
    "    base_model_prefix = \"model\"\n",
    "    _no_split_modules = [\"Qwen2DecoderLayer\"]\n",
    "    _skip_keys_device_placement = [\"past_key_values\"]\n",
    "    \n",
    "    _supports_cache_class = True\n",
    "    \n",
    "    _supports_static_cache = True\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        std = self.config.initializer_range\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=std)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=std)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, Qwen2RMSNorm):\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "\n",
    "def _compute_default_rope_parameters(\n",
    "    config: Optional[PretrainedConfig] = None,\n",
    "    device: Optional[\"torch.device\"] = None,\n",
    "    seq_len: Optional[int] = None,\n",
    "    **rope_kwargs,\n",
    ") -> tuple[\"torch.Tensor\", float]:\n",
    "    \"\"\"\n",
    "    Computes the inverse frequencies according to the original RoPE implementation\n",
    "    Args:\n",
    "        config ([`~transformers.PretrainedConfig`]):\n",
    "            The model configuration.\n",
    "        device (`torch.device`):\n",
    "            The device to use for initialization of the inverse frequencies.\n",
    "        seq_len (`int`, *optional*):\n",
    "            The current sequence length. Unused for this type of RoPE.\n",
    "        rope_kwargs (`Dict`, *optional*):\n",
    "            BC compatibility with the previous RoPE class instantiation, will be removed in v4.45.\n",
    "    Returns:\n",
    "        Tuple of (`torch.Tensor`, `float`), containing the inverse frequencies for the RoPE embeddings and the\n",
    "        post-processing scaling factor applied to the computed cos/sin (unused in this type of RoPE).\n",
    "    \"\"\"\n",
    "    if config is not None and len(rope_kwargs) > 0:\n",
    "        raise ValueError(\n",
    "            \"Unexpected arguments: `**rope_kwargs` and `config` are mutually exclusive in \"\n",
    "            f\"`_compute_default_rope_parameters`, got `rope_kwargs`={rope_kwargs} and `config`={config}\"\n",
    "        )\n",
    "    if len(rope_kwargs) > 0:\n",
    "        base = rope_kwargs[\"base\"]\n",
    "        dim = rope_kwargs[\"dim\"]\n",
    "    elif config is not None:\n",
    "        base = config.rope_theta\n",
    "        partial_rotary_factor = config.partial_rotary_factor if hasattr(config, \"partial_rotary_factor\") else 1.0\n",
    "        head_dim = getattr(config, \"head_dim\", None) or config.hidden_size // config.num_attention_heads\n",
    "        dim = int(head_dim * partial_rotary_factor)\n",
    "\n",
    "    attention_factor = 1.0  # Unused in this type of RoPE\n",
    "\n",
    "    # Compute the inverse frequencies\n",
    "    inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2, dtype=torch.int64).to(device=device, dtype=torch.float) / dim))\n",
    "    return inv_freq, attention_factor\n",
    "    \n",
    "class Qwen2RotaryEmbedding(nn.Module):\n",
    "    def __init__(self, config: Qwen2Config, device=None):\n",
    "        super().__init__()\n",
    "       \n",
    "        self.max_seq_len_cached = config.max_position_embeddings\n",
    "        self.original_max_seq_len = config.max_position_embeddings\n",
    "\n",
    "        self.config = config\n",
    "        self.rope_init_fn = _compute_default_rope_parameters #ROPE_INIT_FUNCTIONS[self.rope_type]\n",
    "\n",
    "        inv_freq, self.attention_scaling = self.rope_init_fn(self.config, device)\n",
    "        self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n",
    "        self.original_inv_freq = self.inv_freq\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, x, position_ids):\n",
    "        inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1).to(x.device)\n",
    "        position_ids_expanded = position_ids[:, None, :].float()\n",
    "\n",
    "        device_type = x.device.type if isinstance(x.device.type, str) and x.device.type != \"mps\" else \"cpu\"\n",
    "        with torch.autocast(device_type=device_type, enabled=False):  # Force float32\n",
    "            freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
    "            emb = torch.cat((freqs, freqs), dim=-1)\n",
    "            cos = emb.cos() * self.attention_scaling\n",
    "            sin = emb.sin() * self.attention_scaling\n",
    "\n",
    "        return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
    "\n",
    "\n",
    "\n",
    "class Qwen2Model(Qwen2PreTrainedModel):\n",
    "    def __init__(self, config: Qwen2Config):\n",
    "        super().__init__(config)\n",
    "        self.padding_idx = config.pad_token_id\n",
    "        self.vocab_size = config.vocab_size\n",
    "\n",
    "        self.embed_tokens = nn.Embedding(config.vocab_size, config.hidden_size, self.padding_idx)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [Qwen2DecoderLayer(config, layer_idx) for layer_idx in range(config.num_hidden_layers)]\n",
    "        )\n",
    "        self.norm = Qwen2RMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n",
    "        self.rotary_emb = Qwen2RotaryEmbedding(config=config)\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.embed_tokens\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.embed_tokens = value\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[Cache] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        cache_position: Optional[torch.LongTensor] = None,\n",
    "        **kwargs,\n",
    "    ) -> BaseModelOutputWithPast:\n",
    "       \n",
    "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "\n",
    "        if (input_ids is None) ^ (inputs_embeds is not None):\n",
    "            raise ValueError(\"You must specify exactly one of input_ids or inputs_embeds\")\n",
    "\n",
    "        if self.gradient_checkpointing and self.training and use_cache:\n",
    "            logger.warning_once(\n",
    "                \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\"\n",
    "            )\n",
    "            use_cache = False\n",
    "\n",
    "        # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache\n",
    "        if not isinstance(past_key_values, (type(None), Cache)):\n",
    "            raise ValueError(\"The `past_key_values` should be either a `Cache` object or `None`.\")\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            inputs_embeds = self.embed_tokens(input_ids)\n",
    "\n",
    "        if use_cache and past_key_values is None:\n",
    "            past_key_values = DynamicCache()\n",
    "\n",
    "        if cache_position is None:\n",
    "            past_seen_tokens = past_key_values.get_seq_length() if past_key_values is not None else 0\n",
    "            cache_position = torch.arange(\n",
    "                past_seen_tokens, past_seen_tokens + inputs_embeds.shape[1], device=inputs_embeds.device\n",
    "            )\n",
    "\n",
    "        if position_ids is None:\n",
    "            position_ids = cache_position.unsqueeze(0)\n",
    "\n",
    "        causal_mask = self._update_causal_mask(\n",
    "            attention_mask, inputs_embeds, cache_position, past_key_values\n",
    "        )\n",
    "\n",
    "        hidden_states = inputs_embeds\n",
    "\n",
    "        # create position embeddings to be shared across the decoder layers\n",
    "        position_embeddings = self.rotary_emb(hidden_states, position_ids)\n",
    "\n",
    "        \n",
    "\n",
    "        for decoder_layer in self.layers[: self.config.num_hidden_layers]:\n",
    "          \n",
    "            layer_outputs = decoder_layer(\n",
    "                hidden_states,\n",
    "                attention_mask=causal_mask,\n",
    "                position_ids=position_ids,\n",
    "                past_key_value=past_key_values,\n",
    "                # output_attentions=output_attentions,\n",
    "                use_cache=use_cache,\n",
    "                cache_position=cache_position,\n",
    "                position_embeddings=position_embeddings,\n",
    "                **kwargs,\n",
    "            )\n",
    "\n",
    "            hidden_states = layer_outputs[0]\n",
    "\n",
    "           \n",
    "\n",
    "        hidden_states = self.norm(hidden_states)\n",
    "\n",
    "        \n",
    "\n",
    "        return BaseModelOutputWithPast(\n",
    "            last_hidden_state=hidden_states,\n",
    "            past_key_values=past_key_values if use_cache else None,\n",
    "            \n",
    "        )\n",
    "\n",
    "    def _update_causal_mask(\n",
    "        self,\n",
    "        attention_mask: Union[torch.Tensor, \"BlockMask\"],\n",
    "        input_tensor: torch.Tensor,\n",
    "        cache_position: torch.Tensor,\n",
    "        past_key_values: Cache,\n",
    "       \n",
    "    ):\n",
    "       \n",
    "        past_seen_tokens = past_key_values.get_seq_length() if past_key_values is not None else 0\n",
    "        using_static_cache = isinstance(past_key_values, StaticCache)\n",
    "       \n",
    "\n",
    "        \n",
    "\n",
    "        dtype = input_tensor.dtype\n",
    "        min_dtype = torch.finfo(dtype).min\n",
    "        sequence_length = input_tensor.shape[1]\n",
    "        # SlidingWindowCache or StaticCache\n",
    "        if using_static_cache:\n",
    "            target_length = past_key_values.get_max_cache_shape()\n",
    "        # DynamicCache or no cache\n",
    "        else:\n",
    "            target_length = (\n",
    "                attention_mask.shape[-1]\n",
    "                if isinstance(attention_mask, torch.Tensor)\n",
    "                else past_seen_tokens + sequence_length + 1\n",
    "            )\n",
    "\n",
    "        # In case the provided `attention` mask is 2D, we generate a causal mask here (4D).\n",
    "        causal_mask = self._prepare_4d_causal_attention_mask_with_cache_position(\n",
    "            attention_mask,\n",
    "            sequence_length=sequence_length,\n",
    "            target_length=target_length,\n",
    "            dtype=dtype,\n",
    "            cache_position=cache_position,\n",
    "            batch_size=input_tensor.shape[0],\n",
    "            \n",
    "            past_key_values=past_key_values,\n",
    "        )\n",
    "\n",
    "\n",
    "        return causal_mask\n",
    "\n",
    "    @staticmethod\n",
    "    def _prepare_4d_causal_attention_mask_with_cache_position(\n",
    "        attention_mask: torch.Tensor,\n",
    "        sequence_length: int,\n",
    "        target_length: int,\n",
    "        dtype: torch.dtype,\n",
    "        cache_position: torch.Tensor,\n",
    "        batch_size: int,\n",
    "       \n",
    "        past_key_values: Cache,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Creates a causal 4D mask of shape `(batch_size, 1, query_length, key_value_length)` from a 2D mask of shape\n",
    "        `(batch_size, key_value_length)`, or if the input `attention_mask` is already 4D, do nothing.\n",
    "\n",
    "        Args:\n",
    "            attention_mask (`torch.Tensor`):\n",
    "                A 2D attention mask of shape `(batch_size, key_value_length)` or a 4D attention mask of shape `(batch_size, 1, query_length, key_value_length)`.\n",
    "            sequence_length (`int`):\n",
    "                The sequence length being processed.\n",
    "            target_length (`int`):\n",
    "                The target length: when generating with static cache, the mask should be as long as the static cache, to account for the 0 padding, the part of the cache that is not filled yet.\n",
    "            dtype (`torch.dtype`):\n",
    "                The dtype to use for the 4D attention mask.\n",
    "            cache_position (`torch.Tensor`):\n",
    "                Indices depicting the position of the input sequence tokens in the sequence.\n",
    "            batch_size (`torch.Tensor`):\n",
    "                Batch size.\n",
    "            config (`Qwen2Config`):\n",
    "                The model's configuration class\n",
    "            past_key_values (`Cache`):\n",
    "                The cache class that is being used currently to generate\n",
    "        \"\"\"\n",
    "        if attention_mask is not None and attention_mask.dim() == 4:\n",
    "            # In this case we assume that the mask comes already in inverted form and requires no inversion or slicing.\n",
    "            causal_mask = attention_mask\n",
    "        else:\n",
    "            min_dtype = torch.finfo(dtype).min\n",
    "            causal_mask = torch.full(\n",
    "                (sequence_length, target_length), fill_value=min_dtype, dtype=dtype, device=cache_position.device\n",
    "            )\n",
    "            diagonal_attend_mask = torch.arange(target_length, device=cache_position.device) > cache_position.reshape(\n",
    "                -1, 1\n",
    "            )\n",
    "            \n",
    "            causal_mask *= diagonal_attend_mask\n",
    "            causal_mask = causal_mask[None, None, :, :].expand(batch_size, 1, -1, -1)\n",
    "            if attention_mask is not None:\n",
    "                causal_mask = causal_mask.clone()  # copy to contiguous memory for in-place edit\n",
    "                if attention_mask.shape[-1] > target_length:\n",
    "                    attention_mask = attention_mask[:, :target_length]\n",
    "                mask_length = attention_mask.shape[-1]\n",
    "                padding_mask = causal_mask[:, :, :, :mask_length] + attention_mask[:, None, None, :].to(\n",
    "                    causal_mask.device\n",
    "                )\n",
    "                padding_mask = padding_mask == 0\n",
    "                causal_mask[:, :, :, :mask_length] = causal_mask[:, :, :, :mask_length].masked_fill(\n",
    "                    padding_mask, min_dtype\n",
    "                )\n",
    "        return causal_mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Qwen2ForCausalLM(Qwen2PreTrainedModel, GenerationMixin):\n",
    "    _tied_weights_keys = [\"lm_head.weight\"]\n",
    "  \n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.model = Qwen2Model(config)\n",
    "        self.vocab_size = config.vocab_size\n",
    "        self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.model.embed_tokens\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.model.embed_tokens = value\n",
    "\n",
    "    def get_output_embeddings(self):\n",
    "        return self.lm_head\n",
    "\n",
    "    def set_output_embeddings(self, new_embeddings):\n",
    "        self.lm_head = new_embeddings\n",
    "\n",
    "    def set_decoder(self, decoder):\n",
    "        self.model = decoder\n",
    "\n",
    "    def get_decoder(self):\n",
    "        return self.model\n",
    "\n",
    "   \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[Cache] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        cache_position: Optional[torch.LongTensor] = None,\n",
    "        logits_to_keep: Union[int, torch.Tensor] = 0,\n",
    "        **kwargs,\n",
    "    ) -> CausalLMOutputWithPast:\n",
    "        \n",
    "       \n",
    "        outputs: BaseModelOutputWithPast = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            use_cache=use_cache,\n",
    "            cache_position=cache_position,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "        # Only compute necessary logits, and do not upcast them to float if we are not computing the loss\n",
    "        slice_indices = slice(-logits_to_keep, None) if isinstance(logits_to_keep, int) else logits_to_keep\n",
    "        logits = self.lm_head(hidden_states[:, slice_indices, :])\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.vocab_size, **kwargs)\n",
    "\n",
    "        return CausalLMOutputWithPast(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            past_key_values=outputs.past_key_values,\n",
    "           \n",
    "        )\n",
    "    def prepare_inputs_for_generation(\n",
    "        self,\n",
    "        input_ids,\n",
    "        past_key_values=None,\n",
    "        attention_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        cache_position=None,\n",
    "        position_ids=None,\n",
    "        use_cache=True,\n",
    "        logits_to_keep=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \n",
    "\n",
    "        model_inputs = super().prepare_inputs_for_generation(\n",
    "            input_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            attention_mask=attention_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            cache_position=cache_position,\n",
    "            position_ids=position_ids,\n",
    "            use_cache=use_cache,\n",
    "            logits_to_keep=logits_to_keep,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        if logits_to_keep is None:\n",
    "            _ = model_inputs.pop(\"logits_to_keep\", None)\n",
    "\n",
    "        if model_inputs[\"inputs_embeds\"] is not None:\n",
    "            batch_size, sequence_length, _ = model_inputs[\"inputs_embeds\"].shape\n",
    "            device = model_inputs[\"inputs_embeds\"].device\n",
    "        else:\n",
    "            batch_size, sequence_length = model_inputs[\"input_ids\"].shape\n",
    "            device = model_inputs[\"input_ids\"].device\n",
    "\n",
    "        # print(sequence_length, past_key_values.get_max_cache_shape())\n",
    "        past_seen_tokens = past_key_values.get_seq_length() if past_key_values is not None else 0\n",
    "        target_length = (\n",
    "                attention_mask.shape[-1]\n",
    "                if isinstance(attention_mask, torch.Tensor)\n",
    "                else past_seen_tokens + sequence_length + 1\n",
    "            )\n",
    "\n",
    "        attention_mask = self.model._prepare_4d_causal_attention_mask_with_cache_position(\n",
    "            attention_mask,\n",
    "            sequence_length=sequence_length,\n",
    "            target_length=target_length,\n",
    "            dtype=self.lm_head.weight.dtype,\n",
    "            cache_position=cache_position,\n",
    "            batch_size=batch_size,\n",
    "            past_key_values=past_key_values\n",
    "        )\n",
    "        model_inputs[\"attention_mask\"] = attention_mask\n",
    "\n",
    "        return model_inputs\n",
    "        \n",
    "    @staticmethod\n",
    "    def _reorder_cache(past_key_values, beam_idx):\n",
    "        reordered_past = ()\n",
    "        for layer_past in past_key_values:\n",
    "            reordered_past += (\n",
    "                tuple(past_state.index_select(0, beam_idx.to(past_state.device)) for past_state in layer_past),\n",
    "            )\n",
    "        return reordered_past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5f02646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:18:31.918501Z",
     "iopub.status.busy": "2025-05-22T17:18:31.918289Z",
     "iopub.status.idle": "2025-05-22T17:18:31.943276Z",
     "shell.execute_reply": "2025-05-22T17:18:31.942703Z"
    },
    "papermill": {
     "duration": 0.03019,
     "end_time": "2025-05-22T17:18:31.944486",
     "exception": false,
     "start_time": "2025-05-22T17:18:31.914296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Optional, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers.generation.utils import GenerateOutput\n",
    "from transformers import LogitsProcessor, LogitsProcessorList, TemperatureLogitsWarper,  AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1147ae52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:18:31.952641Z",
     "iopub.status.busy": "2025-05-22T17:18:31.952426Z",
     "iopub.status.idle": "2025-05-22T17:18:31.969404Z",
     "shell.execute_reply": "2025-05-22T17:18:31.968899Z"
    },
    "papermill": {
     "duration": 0.022578,
     "end_time": "2025-05-22T17:18:31.970486",
     "exception": false,
     "start_time": "2025-05-22T17:18:31.947908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFGLogits(LogitsProcessor):\n",
    "\n",
    "    def __init__(self, cfg, unconditional_inputs, model, verbose=True):\n",
    "        self.cfg = cfg\n",
    "        self.inputs = unconditional_inputs\n",
    "        self.model = model\n",
    "        self.out = None\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def __call__(self, input_ids, scores):\n",
    "        scores = F.log_softmax(scores, dim=-1)\n",
    "        if self.cfg == 1:\n",
    "            return scores\n",
    "        if self.out is None:\n",
    "            self.out = self.model(self.inputs, use_cache=True)\n",
    "        else:\n",
    "            self.out = self.model(input_ids[:, -1:],\n",
    "                                  use_cache=True,\n",
    "                                  past_key_values=self.out.past_key_values)\n",
    "        unconditional_logits = F.log_softmax(self.out.logits[:, -1], dim=-1)\n",
    "        out = self.cfg * (scores - unconditional_logits) + unconditional_logits\n",
    "        return out\n",
    "\n",
    "\n",
    "class SimpARForCausalLM(Qwen2ForCausalLM):\n",
    "    def __init__(self, config):\n",
    "        Qwen2ForCausalLM.__init__(self, config)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def generate_visual_sjd(\n",
    "        self,\n",
    "        inputs,\n",
    "        tokenizer,\n",
    "        **kwargs,\n",
    "    ) -> Union[GenerateOutput, torch.LongTensor]:\n",
    "        \n",
    "        max_steps = kwargs[\"max_new_tokens\"]\n",
    "        height, width = int(math.sqrt(max_steps)), int(math.sqrt(max_steps))\n",
    "        negative_prompt_ids = kwargs.pop(\"negative_prompt_ids\", None)\n",
    "        cfg_scale = kwargs.pop(\"cfg_scale\", 1.0)\n",
    "        temperature = kwargs.pop(\"temperature\", 1.0)\n",
    "        minumum_acc_tokens = kwargs.pop(\"minumum_acc_tokens\", 1)\n",
    "\n",
    "        device = inputs.device\n",
    "        input_length = inputs.size(1)\n",
    "        \n",
    "        accepted_tokens = inputs.clone()\n",
    "        generated_tokens = torch.tensor([], dtype=torch.long, device=device)\n",
    "        draft_tokens = None\n",
    "        prev_draft_probs = None\n",
    "        \n",
    "        for it in range(max_steps):\n",
    "            # 1. Initialize Draft Tokens -------------------------------------------\n",
    "            if draft_tokens is None:\n",
    "                draft_tokens = torch.full(\n",
    "                    (1, max_steps),\n",
    "                    tokenizer.pad_token_id,\n",
    "                    device=device\n",
    "                )\n",
    "            \n",
    "            # 2. Forward Pass + CFG -----------------------------------------------\n",
    "            cond_sequence = torch.cat([accepted_tokens, draft_tokens], dim=1)\n",
    "            logits = self(cond_sequence).logits\n",
    "            cond_draft_logits = logits[:, accepted_tokens.size(1)-1: -1, :]\n",
    "\n",
    "            if cfg_scale > 1.0 and negative_prompt_ids is not None:\n",
    "                neg_sequence = torch.cat([negative_prompt_ids, draft_tokens], dim=1)\n",
    "                uncond_logits = self(neg_sequence).logits\n",
    "                uncond_draft_logits = uncond_logits[:, negative_prompt_ids.size(1)-1: -1, :]\n",
    "                draft_logits = uncond_draft_logits + cfg_scale * (cond_draft_logits - uncond_draft_logits)\n",
    "            else:\n",
    "                draft_logits = cond_draft_logits\n",
    "\n",
    "            # 3. Temperature Scaling ----------------------------------------------\n",
    "            draft_logits /= temperature\n",
    "            draft_probs = F.softmax(draft_logits, dim=-1)\n",
    "\n",
    "            # 4. First Iteration Handling -----------------------------------------\n",
    "            if prev_draft_probs is None:\n",
    "                # Greedy sample first token\n",
    "                draft_tokens = torch.argmax(draft_probs, dim=-1)\n",
    "                first_token = draft_tokens[:, :1]\n",
    "\n",
    "                accepted_tokens = torch.cat([accepted_tokens, first_token], dim=1)\n",
    "                generated_tokens = torch.cat([generated_tokens, first_token], dim=1)\n",
    "\n",
    "                # Update negative prompt if provided\n",
    "                if negative_prompt_ids is not None:\n",
    "                    negative_prompt_ids = torch.cat([negative_prompt_ids, first_token], dim=1)\n",
    "                \n",
    "                prev_draft_probs = draft_probs[:, 1:].detach()\n",
    "                draft_tokens = draft_tokens[:, 1:]\n",
    "                continue  # Skip first iteration verification\n",
    "\n",
    "            # 5. Speculative Verification -----------------------------------------\n",
    "            # Get probabilities for current/previous draft tokens\n",
    "            current_probs = draft_probs.gather(-1, draft_tokens.unsqueeze(-1)).squeeze(-1)\n",
    "            prev_probs = prev_draft_probs.gather(-1, draft_tokens.unsqueeze(-1)).squeeze(-1)\n",
    "            \n",
    "            # Compute acceptance probability (Eq. 1)\n",
    "            alpha = (current_probs / (prev_probs + 1e-8)).clamp(max=1.0)\n",
    "            accept_mask = torch.rand_like(alpha) < alpha\n",
    "\n",
    "            # at least accept several tokens to make sure acceleration\n",
    "            accept_mask[:, 0: minumum_acc_tokens] = True\n",
    "\n",
    "            # 6. Find First Rejection ---------------------------------------------\n",
    "            rejected = (~accept_mask).nonzero(as_tuple=True)\n",
    "            first_reject_pos = rejected[1][0].item() if len(rejected[0]) > 0 else draft_tokens.size(1)\n",
    "\n",
    "            # 7. Update Accepted Tokens -------------------------------------------\n",
    "            new_accepts = draft_tokens[:, :first_reject_pos]\n",
    "            accepted_tokens = torch.cat([accepted_tokens, new_accepts], dim=1)\n",
    "            # Update generated tokens\n",
    "            generated_tokens = torch.cat([generated_tokens, new_accepts], dim=1)\n",
    "\n",
    "            # Update negative prompt if provided\n",
    "            if negative_prompt_ids is not None:\n",
    "                negative_prompt_ids = torch.cat([negative_prompt_ids, new_accepts], dim=1)\n",
    "\n",
    "            # 8. Early Termination Check ------------------------------------------\n",
    "            if accepted_tokens.size(1) - input_length >= max_steps:\n",
    "                print(\"Early termination at iter\", it)\n",
    "                break\n",
    "\n",
    "            # 9. Resample Rejected Tokens (Eq. 2) ---------------------------------\n",
    "            assert first_reject_pos < draft_tokens.size(1)\n",
    "            # Compute calibrated probabilities for first rejected token\n",
    "            residual_probs = (draft_probs - prev_draft_probs).clamp(min=0)\n",
    "            residual_sum = residual_probs.sum(dim=-1, keepdim=True)  # Sum over token dimesion\n",
    "            calibrated_probs = residual_probs / (residual_sum + 1e-8)\n",
    "            \n",
    "            calibrated_probs_slice = calibrated_probs[0, first_reject_pos]\n",
    "            sampled_token = torch.multinomial(calibrated_probs_slice, num_samples=1).unsqueeze(0)\n",
    "            first_reject_token = sampled_token\n",
    "\n",
    "\n",
    "            rest_probs = draft_probs[0, first_reject_pos + 1:]\n",
    "            rest_tokens = torch.multinomial(rest_probs, num_samples=1).transpose(0, 1)\n",
    "\n",
    "            # Rebuild draft tokens and pad to max_steps\n",
    "            draft_tokens = torch.cat([first_reject_token, rest_tokens], dim=1)\n",
    "            # Update prev_draft_probs to match new_draft length\n",
    "            prev_draft_probs = draft_probs[:, first_reject_pos: , :].detach()\n",
    "\n",
    "        # 10. Final Output --------------------------------------------------------\n",
    "        output = accepted_tokens[:, :input_length + max_steps]\n",
    "        if output.size(1) < input_length + max_steps:\n",
    "            padding = torch.full(\n",
    "                (1, input_length + max_steps - output.size(1)),\n",
    "                tokenizer.pad_token_id,\n",
    "                device=device\n",
    "            )\n",
    "            output = torch.cat([output, padding], dim=1)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate_visual(\n",
    "        self,\n",
    "        inputs: Optional[torch.Tensor] = None,\n",
    "        **kwargs,\n",
    "    ) -> Union[GenerateOutput, torch.LongTensor]:\n",
    "        position_ids = kwargs.pop(\"position_ids\", None)\n",
    "        attention_mask = kwargs.pop(\"attention_mask\", None)\n",
    "        negative_prompt_ids = kwargs.pop(\"negative_prompt_ids\", None)\n",
    "        cfg_scale = kwargs.pop(\"cfg_scale\", 1.0)\n",
    "        \n",
    "        return super().generate(\n",
    "            inputs=inputs,\n",
    "            position_ids=position_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            logits_processor=LogitsProcessorList([\n",
    "                CFGLogits(cfg_scale, negative_prompt_ids, self),\n",
    "            ]),\n",
    "            **kwargs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f82ee4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:18:31.977882Z",
     "iopub.status.busy": "2025-05-22T17:18:31.977636Z",
     "iopub.status.idle": "2025-05-22T17:18:39.315135Z",
     "shell.execute_reply": "2025-05-22T17:18:39.314274Z"
    },
    "papermill": {
     "duration": 7.342787,
     "end_time": "2025-05-22T17:18:39.316727",
     "exception": false,
     "start_time": "2025-05-22T17:18:31.973940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf038a1b264f4b309f4aa9a08f31e60e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/822 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e34c5ed7b3424da5093ecf8a51a137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f78c67825b4457cb89da38addd9af6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/247 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adbb5cac139d4319a2bbae476f9152be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/8.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a8a107e4234c8a9623b5b98d8352e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/3.38M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb27f72c07eb4ac0865cd4564274c5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970a0c6fbc544fae85787c02c3d45813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/756 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf3fa188ec04186a9b228c9e2920cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "model_name = \"Daniel0724/SimpleAR-0.5B-RL\"\n",
    "\n",
    "# define your prompt here:\n",
    "\n",
    "\n",
    "# Load LLM and tokenizer\n",
    "model = SimpARForCausalLM.from_pretrained(model_name, device_map=device, torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aa902e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:18:39.333103Z",
     "iopub.status.busy": "2025-05-22T17:18:39.332750Z",
     "iopub.status.idle": "2025-05-22T17:18:48.423087Z",
     "shell.execute_reply": "2025-05-22T17:18:48.422273Z"
    },
    "papermill": {
     "duration": 9.101069,
     "end_time": "2025-05-22T17:18:48.424598",
     "exception": false,
     "start_time": "2025-05-22T17:18:39.323529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting loguru\r\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\r\n",
      "Collecting mediapy\r\n",
      "  Downloading mediapy-1.2.4-py3-none-any.whl.metadata (4.8 kB)\r\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from mediapy) (7.34.0)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapy) (3.7.2)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mediapy) (1.26.4)\r\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from mediapy) (11.1.0)\r\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (75.2.0)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (0.19.2)\r\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (4.4.2)\r\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (0.7.5)\r\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (5.7.1)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (3.0.50)\r\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (2.19.1)\r\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (0.2.0)\r\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (0.1.7)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy) (4.9.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy) (4.57.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy) (25.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->mediapy) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->mediapy) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->mediapy) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->mediapy) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->mediapy) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->mediapy) (2.4.1)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->mediapy) (0.8.4)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->mediapy) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->mediapy) (0.2.13)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapy) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->mediapy) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->mediapy) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->mediapy) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->mediapy) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->mediapy) (2024.2.0)\r\n",
      "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mediapy-1.2.4-py3-none-any.whl (26 kB)\r\n",
      "Installing collected packages: loguru, mediapy\r\n",
      "Successfully installed loguru-0.7.3 mediapy-1.2.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install loguru mediapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7bef57a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:18:48.435382Z",
     "iopub.status.busy": "2025-05-22T17:18:48.435099Z",
     "iopub.status.idle": "2025-05-22T17:18:51.141897Z",
     "shell.execute_reply": "2025-05-22T17:18:51.140842Z"
    },
    "papermill": {
     "duration": 2.713677,
     "end_time": "2025-05-22T17:18:51.143544",
     "exception": false,
     "start_time": "2025-05-22T17:18:48.429867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SimpleAR'...\r\n",
      "remote: Enumerating objects: 5520, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (39/39), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (20/20), done.\u001b[K\r\n",
      "remote: Total 5520 (delta 29), reused 19 (delta 19), pack-reused 5481 (from 2)\u001b[K\r\n",
      "Receiving objects: 100% (5520/5520), 42.71 MiB | 29.17 MiB/s, done.\r\n",
      "Resolving deltas: 100% (1340/1340), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/wdrink/SimpleAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bb9719a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:18:51.156157Z",
     "iopub.status.busy": "2025-05-22T17:18:51.155897Z",
     "iopub.status.idle": "2025-05-22T17:18:51.160200Z",
     "shell.execute_reply": "2025-05-22T17:18:51.159427Z"
    },
    "papermill": {
     "duration": 0.011966,
     "end_time": "2025-05-22T17:18:51.161392",
     "exception": false,
     "start_time": "2025-05-22T17:18:51.149426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../working/SimpleAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a2402b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:18:51.172875Z",
     "iopub.status.busy": "2025-05-22T17:18:51.172628Z",
     "iopub.status.idle": "2025-05-22T17:18:51.292607Z",
     "shell.execute_reply": "2025-05-22T17:18:51.291663Z"
    },
    "papermill": {
     "duration": 0.127466,
     "end_time": "2025-05-22T17:18:51.294185",
     "exception": false,
     "start_time": "2025-05-22T17:18:51.166719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import SimpARForCausalLM from llava.language_model.simpar_qwen2. Error: cannot import name 'LogitsWarper' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "from simpar.model.tokenizer.cosmos_tokenizer.networks import TokenizerConfigs\n",
    "from simpar.model.tokenizer.cosmos_tokenizer.video_lib import CausalVideoTokenizer as CosmosTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f68559ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:18:51.306916Z",
     "iopub.status.busy": "2025-05-22T17:18:51.306268Z",
     "iopub.status.idle": "2025-05-22T17:18:56.532389Z",
     "shell.execute_reply": "2025-05-22T17:18:56.531621Z"
    },
    "papermill": {
     "duration": 5.23418,
     "end_time": "2025-05-22T17:18:56.534064",
     "exception": false,
     "start_time": "2025-05-22T17:18:51.299884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-22 17:18:51.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msimpar.model.tokenizer.cosmos_tokenizer.modules.layers3d\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m930\u001b[0m - \u001b[1mWorking with z of shape (1, 16, 64, 64) = 65536 dimensions.\u001b[0m\n",
      "\u001b[32m2025-05-22 17:18:52.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msimpar.model.tokenizer.cosmos_tokenizer.networks.discrete_video\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mDV based on FSQ-VAE, with {'attn_resolutions': [32], 'channels': 128, 'channels_mult': [2, 4, 4], 'dropout': 0.0, 'in_channels': 3, 'num_res_blocks': 2, 'out_channels': 3, 'resolution': 1024, 'patch_size': 4, 'patch_method': 'haar', 'num_groups': 1, 'legacy_mode': False, 'spatial_compression': 16, 'temporal_compression': 8, 'quantizer': 'FSQ', 'levels': [8, 8, 8, 5, 5, 5], 'encoder': 'FACTORIZED', 'decoder': 'FACTORIZED', 'name': 'DV'}.\u001b[0m\n",
      "\u001b[32m2025-05-22 17:18:52.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msimpar.model.tokenizer.cosmos_tokenizer.networks.discrete_video\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mmodel=DV, num_parameters=112,472,182\u001b[0m\n",
      "\u001b[32m2025-05-22 17:18:52.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msimpar.model.tokenizer.cosmos_tokenizer.networks.discrete_video\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mz_channels=16, embedding_dim=6.\u001b[0m\n",
      "\u001b[32m2025-05-22 17:18:54.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msimpar.model.tokenizer.cosmos_tokenizer.modules.layers3d\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m930\u001b[0m - \u001b[1mWorking with z of shape (1, 16, 64, 64) = 65536 dimensions.\u001b[0m\n",
      "\u001b[32m2025-05-22 17:18:55.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msimpar.model.tokenizer.cosmos_tokenizer.networks.discrete_video\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mDV based on FSQ-VAE, with {'attn_resolutions': [32], 'channels': 128, 'channels_mult': [2, 4, 4], 'dropout': 0.0, 'in_channels': 3, 'num_res_blocks': 2, 'out_channels': 3, 'resolution': 1024, 'patch_size': 4, 'patch_method': 'haar', 'num_groups': 1, 'legacy_mode': False, 'spatial_compression': 16, 'temporal_compression': 8, 'quantizer': 'FSQ', 'levels': [8, 8, 8, 5, 5, 5], 'encoder': 'FACTORIZED', 'decoder': 'FACTORIZED', 'name': 'DV'}.\u001b[0m\n",
      "\u001b[32m2025-05-22 17:18:55.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msimpar.model.tokenizer.cosmos_tokenizer.networks.discrete_video\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mmodel=DV, num_parameters=112,472,182\u001b[0m\n",
      "\u001b[32m2025-05-22 17:18:55.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msimpar.model.tokenizer.cosmos_tokenizer.networks.discrete_video\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mz_channels=16, embedding_dim=6.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CausalVideoTokenizer(\n",
       "  (_enc_model): Sequential(\n",
       "    (encoder): EncoderFactorized(\n",
       "      (patcher3d): Patcher3D()\n",
       "      (conv_in): Sequential(\n",
       "        (0): CausalConv3d(\n",
       "          (conv3d): Conv3d(192, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "        )\n",
       "        (1): CausalConv3d(\n",
       "          (conv3d): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "        )\n",
       "      )\n",
       "      (down): ModuleList(\n",
       "        (0): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): CausalResnetBlockFactorized3d(\n",
       "              (norm1): CausalNormalize(\n",
       "                (norm): GroupNorm(1, 128, eps=1e-06, affine=True)\n",
       "              )\n",
       "              (conv1): Sequential(\n",
       "                (0): CausalConv3d(\n",
       "                  (conv3d): Conv3d(128, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "                )\n",
       "                (1): CausalConv3d(\n",
       "                  (conv3d): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "                )\n",
       "              )\n",
       "              (norm2): CausalNormalize(\n",
       "                (norm): GroupNorm(1, 256, eps=1e-06, affine=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Sequential(\n",
       "                (0): CausalConv3d(\n",
       "                  (conv3d): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "                )\n",
       "                (1): CausalConv3d(\n",
       "                  (conv3d): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "                )\n",
       "              )\n",
       "              (nin_shortcut): CausalConv3d(\n",
       "                (conv3d): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "            )\n",
       "            (1): CausalResnetBlockFactorized3d(\n",
       "              (norm1): CausalNormalize(\n",
       "                (norm): GroupNorm(1, 256, eps=1e-06, affine=True)\n",
       "              )\n",
       "              (conv1): Sequential(\n",
       "                (0): CausalConv3d(\n",
       "                  (conv3d): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "                )\n",
       "                (1): CausalConv3d(\n",
       "                  (conv3d): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "                )\n",
       "              )\n",
       "              (norm2): CausalNormalize(\n",
       "                (norm): GroupNorm(1, 256, eps=1e-06, affine=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Sequential(\n",
       "                (0): CausalConv3d(\n",
       "                  (conv3d): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "                )\n",
       "                (1): CausalConv3d(\n",
       "                  (conv3d): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "                )\n",
       "              )\n",
       "              (nin_shortcut): Identity()\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (downsample): CausalHybridDownsample3d(\n",
       "            (conv1): CausalConv3d(\n",
       "              (conv3d): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2))\n",
       "            )\n",
       "            (conv2): CausalConv3d(\n",
       "              (conv3d): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(2, 1, 1))\n",
       "            )\n",
       "            (conv3): CausalConv3d(\n",
       "              (conv3d): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): CausalResnetBlockFactorized3d(\n",
       "              (norm1): CausalNormalize(\n",
       "                (norm): GroupNorm(1, 256, eps=1e-06, affine=True)\n",
       "              )\n",
       "              (conv1): Sequential(\n",
       "                (0): CausalConv3d(\n",
       "                  (conv3d): Conv3d(256, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "                )\n",
       "                (1): CausalConv3d(\n",
       "                  (conv3d): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "                )\n",
       "              )\n",
       "              (norm2): CausalNormalize(\n",
       "                (norm): GroupNorm(1, 512, eps=1e-06, affine=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Sequential(\n",
       "                (0): CausalConv3d(\n",
       "                  (conv3d): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "                )\n",
       "                (1): CausalConv3d(\n",
       "                  (conv3d): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "                )\n",
       "              )\n",
       "              (nin_shortcut): CausalConv3d(\n",
       "                (conv3d): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "            )\n",
       "            (1): CausalResnetBlockFactorized3d(\n",
       "              (norm1): CausalNormalize(\n",
       "                (norm): GroupNorm(1, 512, eps=1e-06, affine=True)\n",
       "              )\n",
       "              (conv1): Sequential(\n",
       "                (0): CausalConv3d(\n",
       "                  (conv3d): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "                )\n",
       "                (1): CausalConv3d(\n",
       "                  (conv3d): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "                )\n",
       "              )\n",
       "              (norm2): CausalNormalize(\n",
       "                (norm): GroupNorm(1, 512, eps=1e-06, affine=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Sequential(\n",
       "                (0): CausalConv3d(\n",
       "                  (conv3d): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "                )\n",
       "                (1): CausalConv3d(\n",
       "                  (conv3d): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "                )\n",
       "              )\n",
       "              (nin_shortcut): Identity()\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (downsample): CausalHybridDownsample3d(\n",
       "            (conv1): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2))\n",
       "            )\n",
       "            (conv2): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(2, 1, 1))\n",
       "            )\n",
       "            (conv3): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): Module(\n",
       "          (block): ModuleList(\n",
       "            (0-1): 2 x CausalResnetBlockFactorized3d(\n",
       "              (norm1): CausalNormalize(\n",
       "                (norm): GroupNorm(1, 512, eps=1e-06, affine=True)\n",
       "              )\n",
       "              (conv1): Sequential(\n",
       "                (0): CausalConv3d(\n",
       "                  (conv3d): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "                )\n",
       "                (1): CausalConv3d(\n",
       "                  (conv3d): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "                )\n",
       "              )\n",
       "              (norm2): CausalNormalize(\n",
       "                (norm): GroupNorm(1, 512, eps=1e-06, affine=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Sequential(\n",
       "                (0): CausalConv3d(\n",
       "                  (conv3d): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "                )\n",
       "                (1): CausalConv3d(\n",
       "                  (conv3d): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "                )\n",
       "              )\n",
       "              (nin_shortcut): Identity()\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "        )\n",
       "      )\n",
       "      (mid): Module(\n",
       "        (block_1): CausalResnetBlockFactorized3d(\n",
       "          (norm1): CausalNormalize(\n",
       "            (norm): GroupNorm(1, 512, eps=1e-06, affine=True)\n",
       "          )\n",
       "          (conv1): Sequential(\n",
       "            (0): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "            )\n",
       "            (1): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "          (norm2): CausalNormalize(\n",
       "            (norm): GroupNorm(1, 512, eps=1e-06, affine=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Sequential(\n",
       "            (0): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "            )\n",
       "            (1): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "          (nin_shortcut): Identity()\n",
       "        )\n",
       "        (attn_1): Sequential(\n",
       "          (0): CausalAttnBlock(\n",
       "            (norm): CausalNormalize(\n",
       "              (norm): GroupNorm(1, 512, eps=1e-06, affine=True)\n",
       "            )\n",
       "            (q): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "            (k): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "            (v): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "            (proj_out): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "          (1): CausalTemporalAttnBlock(\n",
       "            (norm): CausalNormalize(\n",
       "              (norm): GroupNorm(1, 512, eps=1e-06, affine=True)\n",
       "            )\n",
       "            (q): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "            (k): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "            (v): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "            (proj_out): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (block_2): CausalResnetBlockFactorized3d(\n",
       "          (norm1): CausalNormalize(\n",
       "            (norm): GroupNorm(1, 512, eps=1e-06, affine=True)\n",
       "          )\n",
       "          (conv1): Sequential(\n",
       "            (0): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "            )\n",
       "            (1): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "          (norm2): CausalNormalize(\n",
       "            (norm): GroupNorm(1, 512, eps=1e-06, affine=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Sequential(\n",
       "            (0): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "            )\n",
       "            (1): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "          (nin_shortcut): Identity()\n",
       "        )\n",
       "      )\n",
       "      (norm_out): CausalNormalize(\n",
       "        (norm): GroupNorm(1, 512, eps=1e-06, affine=True)\n",
       "      )\n",
       "      (conv_out): Sequential(\n",
       "        (0): CausalConv3d(\n",
       "          (conv3d): Conv3d(512, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "        )\n",
       "        (1): CausalConv3d(\n",
       "          (conv3d): Conv3d(16, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (quant_conv): CausalConv3d(\n",
       "      (conv3d): Conv3d(16, 6, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "    (quantizer): FSQuantizer(\n",
       "      (project_in): Identity()\n",
       "      (project_out): Identity()\n",
       "    )\n",
       "  )\n",
       "  (_dec_model): Sequential(\n",
       "    (inv_quant): InvQuantizerJit(\n",
       "      (quantizer): FSQuantizer(\n",
       "        (project_in): Identity()\n",
       "        (project_out): Identity()\n",
       "      )\n",
       "    )\n",
       "    (post_quant_conv): CausalConv3d(\n",
       "      (conv3d): Conv3d(6, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "    (decoder): DecoderFactorized(\n",
       "      (unpatcher3d): UnPatcher3D()\n",
       "      (conv_in): Sequential(\n",
       "        (0): CausalConv3d(\n",
       "          (conv3d): Conv3d(16, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "        )\n",
       "        (1): CausalConv3d(\n",
       "          (conv3d): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "        )\n",
       "      )\n",
       "      (mid): Module(\n",
       "        (block_1): CausalResnetBlockFactorized3d(\n",
       "          (norm1): CausalNormalize(\n",
       "            (norm): GroupNorm(1, 512, eps=1e-06, affine=True)\n",
       "          )\n",
       "          (conv1): Sequential(\n",
       "            (0): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "            )\n",
       "            (1): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "          (norm2): CausalNormalize(\n",
       "            (norm): GroupNorm(1, 512, eps=1e-06, affine=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Sequential(\n",
       "            (0): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "            )\n",
       "            (1): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "          (nin_shortcut): Identity()\n",
       "        )\n",
       "        (attn_1): Sequential(\n",
       "          (0): CausalAttnBlock(\n",
       "            (norm): CausalNormalize(\n",
       "              (norm): GroupNorm(1, 512, eps=1e-06, affine=True)\n",
       "            )\n",
       "            (q): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "            (k): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "            (v): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "            (proj_out): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "          (1): CausalTemporalAttnBlock(\n",
       "            (norm): CausalNormalize(\n",
       "              (norm): GroupNorm(1, 512, eps=1e-06, affine=True)\n",
       "            )\n",
       "            (q): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "            (k): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "            (v): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "            (proj_out): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (block_2): CausalResnetBlockFactorized3d(\n",
       "          (norm1): CausalNormalize(\n",
       "            (norm): GroupNorm(1, 512, eps=1e-06, affine=True)\n",
       "          )\n",
       "          (conv1): Sequential(\n",
       "            (0): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "            )\n",
       "            (1): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "          (norm2): CausalNormalize(\n",
       "            (norm): GroupNorm(1, 512, eps=1e-06, affine=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Sequential(\n",
       "            (0): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "            )\n",
       "            (1): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "          (nin_shortcut): Identity()\n",
       "        )\n",
       "      )\n",
       "      (up): ModuleList(\n",
       "        (0): Module(\n",
       "          (block): ModuleList(\n",
       "            (0): CausalResnetBlockFactorized3d(\n",
       "              (norm1): CausalNormalize(\n",
       "                (norm): GroupNorm(1, 512, eps=1e-06, affine=True)\n",
       "              )\n",
       "              (conv1): Sequential(\n",
       "                (0): CausalConv3d(\n",
       "                  (conv3d): Conv3d(512, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "                )\n",
       "                (1): CausalConv3d(\n",
       "                  (conv3d): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "                )\n",
       "              )\n",
       "              (norm2): CausalNormalize(\n",
       "                (norm): GroupNorm(1, 256, eps=1e-06, affine=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Sequential(\n",
       "                (0): CausalConv3d(\n",
       "                  (conv3d): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "                )\n",
       "                (1): CausalConv3d(\n",
       "                  (conv3d): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "                )\n",
       "              )\n",
       "              (nin_shortcut): CausalConv3d(\n",
       "                (conv3d): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "              )\n",
       "            )\n",
       "            (1-2): 2 x CausalResnetBlockFactorized3d(\n",
       "              (norm1): CausalNormalize(\n",
       "                (norm): GroupNorm(1, 256, eps=1e-06, affine=True)\n",
       "              )\n",
       "              (conv1): Sequential(\n",
       "                (0): CausalConv3d(\n",
       "                  (conv3d): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "                )\n",
       "                (1): CausalConv3d(\n",
       "                  (conv3d): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "                )\n",
       "              )\n",
       "              (norm2): CausalNormalize(\n",
       "                (norm): GroupNorm(1, 256, eps=1e-06, affine=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Sequential(\n",
       "                (0): CausalConv3d(\n",
       "                  (conv3d): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "                )\n",
       "                (1): CausalConv3d(\n",
       "                  (conv3d): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "                )\n",
       "              )\n",
       "              (nin_shortcut): Identity()\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "        )\n",
       "        (1-2): 2 x Module(\n",
       "          (block): ModuleList(\n",
       "            (0-2): 3 x CausalResnetBlockFactorized3d(\n",
       "              (norm1): CausalNormalize(\n",
       "                (norm): GroupNorm(1, 512, eps=1e-06, affine=True)\n",
       "              )\n",
       "              (conv1): Sequential(\n",
       "                (0): CausalConv3d(\n",
       "                  (conv3d): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "                )\n",
       "                (1): CausalConv3d(\n",
       "                  (conv3d): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "                )\n",
       "              )\n",
       "              (norm2): CausalNormalize(\n",
       "                (norm): GroupNorm(1, 512, eps=1e-06, affine=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv2): Sequential(\n",
       "                (0): CausalConv3d(\n",
       "                  (conv3d): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "                )\n",
       "                (1): CausalConv3d(\n",
       "                  (conv3d): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "                )\n",
       "              )\n",
       "              (nin_shortcut): Identity()\n",
       "            )\n",
       "          )\n",
       "          (attn): ModuleList()\n",
       "          (upsample): CausalHybridUpsample3d(\n",
       "            (conv1): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "            (conv2): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "            )\n",
       "            (conv3): CausalConv3d(\n",
       "              (conv3d): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_out): CausalNormalize(\n",
       "        (norm): GroupNorm(1, 256, eps=1e-06, affine=True)\n",
       "      )\n",
       "      (conv_out): Sequential(\n",
       "        (0): CausalConv3d(\n",
       "          (conv3d): Conv3d(256, 192, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
       "        )\n",
       "        (1): CausalConv3d(\n",
       "          (conv3d): Conv3d(192, 192, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Cosmos tokenizer\n",
    "tokenizer_config = TokenizerConfigs[\"DV\"].value\n",
    "tokenizer_config.update(dict(spatial_compression=16, temporal_compression=8))\n",
    "vq_model = CosmosTokenizer(checkpoint_enc=f\"../input/cosmos-1-0-tokenizer-dv8x16x16/encoder.jit\", checkpoint_dec=f\"../input/cosmos-1-0-tokenizer-dv8x16x16/decoder.jit\", tokenizer_config=tokenizer_config)\n",
    "vq_model.to(device)\n",
    "vq_model.eval()\n",
    "vq_model.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "110ec0c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:18:56.555508Z",
     "iopub.status.busy": "2025-05-22T17:18:56.554671Z",
     "iopub.status.idle": "2025-05-22T17:22:42.152476Z",
     "shell.execute_reply": "2025-05-22T17:22:42.151811Z"
    },
    "papermill": {
     "duration": 225.607487,
     "end_time": "2025-05-22T17:22:42.153992",
     "exception": false,
     "start_time": "2025-05-22T17:18:56.546505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "codebook_size = 64000\n",
    "latent_size = 64\n",
    "prompt = \"a photo of a baseball glove below an umbrella\"\n",
    "format_prompt = \"<|t2i|>\" + \"A highly realistic image of \" + prompt + \"<|soi|>\"\n",
    "input_ids = tokenizer(format_prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "uncond_prompt = \"<|t2i|>\" + \"An image of aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion\" + \"<|soi|>\"\n",
    "uncond_input_ids = tokenizer(uncond_prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "# next token prediction\n",
    "with torch.inference_mode():\n",
    "    output_ids = model.generate_visual(\n",
    "        input_ids,\n",
    "        negative_prompt_ids=uncond_input_ids,\n",
    "        cfg_scale=6.0,\n",
    "        do_sample=True,\n",
    "        temperature=1.0,\n",
    "        top_p=1.0,\n",
    "        top_k=64000,\n",
    "        max_new_tokens=4096,\n",
    "        use_cache=True\n",
    "    )\n",
    "\n",
    "index_sample = output_ids[:, input_ids.shape[1]: input_ids.shape[1] + 4096].clone()\n",
    "index_sample = index_sample - len(tokenizer)\n",
    "index_sample = torch.clamp(index_sample, min=0, max=codebook_size-1)\n",
    "index_sample = index_sample.reshape(-1, latent_size, latent_size).unsqueeze(1)\n",
    "\n",
    "# decode with tokenizer\n",
    "with torch.inference_mode():\n",
    "    samples = vq_model.decode(index_sample)\n",
    "\n",
    "samples = samples.squeeze(2)\n",
    "save_image(samples, os.path.join(f\"{prompt[:50]}.png\"), normalize=True, value_range=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18ada174",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:22:42.168116Z",
     "iopub.status.busy": "2025-05-22T17:22:42.167883Z",
     "iopub.status.idle": "2025-05-22T17:26:22.869808Z",
     "shell.execute_reply": "2025-05-22T17:26:22.868933Z"
    },
    "papermill": {
     "duration": 220.710411,
     "end_time": "2025-05-22T17:26:22.871358",
     "exception": false,
     "start_time": "2025-05-22T17:22:42.160947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"a photo of a wine glass above a kite\"\n",
    "format_prompt = \"<|t2i|>\" + \"A highly realistic image of \" + prompt + \"<|soi|>\"\n",
    "input_ids = tokenizer(format_prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "uncond_prompt = \"<|t2i|>\" + \"An image of aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion\" + \"<|soi|>\"\n",
    "uncond_input_ids = tokenizer(uncond_prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "# next token prediction\n",
    "with torch.inference_mode():\n",
    "    output_ids = model.generate_visual(\n",
    "        input_ids,\n",
    "        negative_prompt_ids=uncond_input_ids,\n",
    "        cfg_scale=6.0,\n",
    "        do_sample=True,\n",
    "        temperature=1.0,\n",
    "        top_p=1.0,\n",
    "        top_k=64000,\n",
    "        max_new_tokens=4096,\n",
    "        use_cache=True\n",
    "    )\n",
    "\n",
    "index_sample = output_ids[:, input_ids.shape[1]: input_ids.shape[1] + 4096].clone()\n",
    "index_sample = index_sample - len(tokenizer)\n",
    "index_sample = torch.clamp(index_sample, min=0, max=codebook_size-1)\n",
    "index_sample = index_sample.reshape(-1, latent_size, latent_size).unsqueeze(1)\n",
    "\n",
    "# decode with tokenizer\n",
    "with torch.inference_mode():\n",
    "    samples = vq_model.decode(index_sample)\n",
    "\n",
    "samples = samples.squeeze(2)\n",
    "save_image(samples, os.path.join(f\"{prompt[:50]}.png\"), normalize=True, value_range=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97dc7317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T17:26:22.885545Z",
     "iopub.status.busy": "2025-05-22T17:26:22.885092Z",
     "iopub.status.idle": "2025-05-22T17:30:03.314791Z",
     "shell.execute_reply": "2025-05-22T17:30:03.313927Z"
    },
    "papermill": {
     "duration": 220.438592,
     "end_time": "2025-05-22T17:30:03.316799",
     "exception": false,
     "start_time": "2025-05-22T17:26:22.878207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"a photo of a white wine glass and a brown giraffe\"\n",
    "format_prompt = \"<|t2i|>\" + \"A highly realistic image of \" + prompt + \"<|soi|>\"\n",
    "input_ids = tokenizer(format_prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "uncond_prompt = \"<|t2i|>\" + \"An image of aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion\" + \"<|soi|>\"\n",
    "uncond_input_ids = tokenizer(uncond_prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "# next token prediction\n",
    "with torch.inference_mode():\n",
    "    output_ids = model.generate_visual(\n",
    "        input_ids,\n",
    "        negative_prompt_ids=uncond_input_ids,\n",
    "        cfg_scale=6.0,\n",
    "        do_sample=True,\n",
    "        temperature=1.0,\n",
    "        top_p=1.0,\n",
    "        top_k=64000,\n",
    "        max_new_tokens=4096,\n",
    "        use_cache=True\n",
    "    )\n",
    "\n",
    "index_sample = output_ids[:, input_ids.shape[1]: input_ids.shape[1] + 4096].clone()\n",
    "index_sample = index_sample - len(tokenizer)\n",
    "index_sample = torch.clamp(index_sample, min=0, max=codebook_size-1)\n",
    "index_sample = index_sample.reshape(-1, latent_size, latent_size).unsqueeze(1)\n",
    "\n",
    "# decode with tokenizer\n",
    "with torch.inference_mode():\n",
    "    samples = vq_model.decode(index_sample)\n",
    "\n",
    "samples = samples.squeeze(2)\n",
    "save_image(samples, os.path.join(f\"{prompt[:50]}.png\"), normalize=True, value_range=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec29ee37",
   "metadata": {
    "papermill": {
     "duration": 0.010619,
     "end_time": "2025-05-22T17:30:03.339374",
     "exception": false,
     "start_time": "2025-05-22T17:30:03.328755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7429614,
     "sourceId": 11826898,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 731.687084,
   "end_time": "2025-05-22T17:30:06.380011",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-22T17:17:54.692927",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "067a24faf8bd4a77a799c4c6078fc0a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_96c89900b05f4f4f9d24d223bb9d64e8",
       "placeholder": "​",
       "style": "IPY_MODEL_f5ca1f0ce9894b539ffdd7104e1c8b64",
       "tabbable": null,
       "tooltip": null,
       "value": " 3.38M/3.38M [00:00&lt;00:00, 8.15MB/s]"
      }
     },
     "074567e5662b4a81b45473527592c1d2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "091652d97c0d4a93b5b1fe0106c91387": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5a20d89078bd474a9cd8a6f59f0cb8e8",
       "max": 438.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5c47f907783a414b9768aad12145eb06",
       "tabbable": null,
       "tooltip": null,
       "value": 438.0
      }
     },
     "0cf5c093544647668f8f1b015bb92b2e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0fb72b98c14446688ebfdeaf27d07a6a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d50cba37e2544fa2aaa8def85301013b",
       "max": 8408.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_da85ba8cd9534d319c2851fc709c7ee8",
       "tabbable": null,
       "tooltip": null,
       "value": 8408.0
      }
     },
     "182404b9b77c4b16b20556950b1cc079": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "20f296a6ce5c430e93ab61f8806142ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "295c6ab6b1a940ab830337bfaba39e1b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2b752c562398426bab3578dd5c9d0f35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4fffff9d401d4b9f99af95cf6e9d7d78",
       "placeholder": "​",
       "style": "IPY_MODEL_f65a0f2866f4443fb4a34c96d6d9308d",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.10G/1.10G [00:02&lt;00:00, 392MB/s]"
      }
     },
     "320e0e0db48e48cba14a1f0f1a1a3969": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6155ed31bbf3448a8d08f4fe993ae72e",
       "placeholder": "​",
       "style": "IPY_MODEL_560376928f324f379e6d3c633012f6e7",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "391a8efb3bdd4a45a5161c1e659d2e85": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3cfbf61293fe4285a30c01c613458d6e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ef10ad8ac56a4a39be82de5b4975a865",
       "placeholder": "​",
       "style": "IPY_MODEL_4bd75d3fc04e485ea4c2062b104d13b0",
       "tabbable": null,
       "tooltip": null,
       "value": " 756/756 [00:00&lt;00:00, 91.0kB/s]"
      }
     },
     "3dc5b9806c8c4f73adbad394ff2eea3f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3f78c67825b4457cb89da38addd9af6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8e1b8ed3f0ba455182bab1301771b94a",
        "IPY_MODEL_67da9c48791f48adb68efde0b600c484",
        "IPY_MODEL_c7c81a507c4649019133aca2bf4bda14"
       ],
       "layout": "IPY_MODEL_20f296a6ce5c430e93ab61f8806142ff",
       "tabbable": null,
       "tooltip": null
      }
     },
     "421e580d500b4c4b9cffac45dd78aed0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4e4661b86914472a954e2d96f42c6ba5",
       "max": 822.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_51a9bc0085f645758c9e02f6b5d8957e",
       "tabbable": null,
       "tooltip": null,
       "value": 822.0
      }
     },
     "47e34c5ed7b3424da5093ecf8a51a137": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a4e9ff98f7c44216852da5fa49603fa1",
        "IPY_MODEL_f342f38b2900477e86666ed4bf20c661",
        "IPY_MODEL_2b752c562398426bab3578dd5c9d0f35"
       ],
       "layout": "IPY_MODEL_ae646d4402db4b9485582aed8959661e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4bd75d3fc04e485ea4c2062b104d13b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4ce18d12636f43a9b6a6b93c8de3ebfd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4e0a7c4b632e4bb7b74b24225af5a779": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9ade8b63975240cbab64381d449bbb17",
       "max": 3383407.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_abe1bebc0a4d4fc6b7c353a8e97ebf5a",
       "tabbable": null,
       "tooltip": null,
       "value": 3383407.0
      }
     },
     "4e4661b86914472a954e2d96f42c6ba5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4ef9ed232068497d91bf5edcd1a33715": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4f1a2e47f5f54eed8075dd7b79891139": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4fffff9d401d4b9f99af95cf6e9d7d78": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "51a9bc0085f645758c9e02f6b5d8957e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "51f32d1bef96489e9cd08db935834ce0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4ef9ed232068497d91bf5edcd1a33715",
       "placeholder": "​",
       "style": "IPY_MODEL_7b1711500bef40cf9ae2b07d8c2e3542",
       "tabbable": null,
       "tooltip": null,
       "value": "merges.txt: 100%"
      }
     },
     "55d66701dbac420a9b2ec7af6fb146b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f456daa7ef9c4752915505c77ef7d1d6",
       "placeholder": "​",
       "style": "IPY_MODEL_b0f3955c9ce94007838874e46cc4e6f2",
       "tabbable": null,
       "tooltip": null,
       "value": " 438/438 [00:00&lt;00:00, 54.5kB/s]"
      }
     },
     "560376928f324f379e6d3c633012f6e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "575906c9f4554223b9ea9f120a653c58": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5829beccb04c4847aee70f4095b41f9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b0da95f331134fc8933ccc576a833cf3",
       "placeholder": "​",
       "style": "IPY_MODEL_e8db43f175344ad4b18066819d0e12f4",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.67M/1.67M [00:00&lt;00:00, 5.05MB/s]"
      }
     },
     "5a20d89078bd474a9cd8a6f59f0cb8e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5a5fcbd627dd43ab85eb551ec677e65c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b33fd0b9fa04e0eb510ed453349dfdf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_074567e5662b4a81b45473527592c1d2",
       "max": 756.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_aa51b39d46174140b9603faaabba2d4c",
       "tabbable": null,
       "tooltip": null,
       "value": 756.0
      }
     },
     "5c47f907783a414b9768aad12145eb06": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "60a8a107e4234c8a9623b5b98d8352e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9cef60211e3146b98d63a5440bc4e68c",
        "IPY_MODEL_4e0a7c4b632e4bb7b74b24225af5a779",
        "IPY_MODEL_067a24faf8bd4a77a799c4c6078fc0a2"
       ],
       "layout": "IPY_MODEL_980db4513606422697a5388bb87cc600",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6155ed31bbf3448a8d08f4fe993ae72e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "64b70dee2765448cac3d0673489a2d05": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "67934394d58f40b7aac2c9d6f2355186": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "67da9c48791f48adb68efde0b600c484": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_67934394d58f40b7aac2c9d6f2355186",
       "max": 247.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e0c30bc790044174b035e11afe7e31d0",
       "tabbable": null,
       "tooltip": null,
       "value": 247.0
      }
     },
     "6953d0ddb200413e8f54b6922db30837": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_295c6ab6b1a940ab830337bfaba39e1b",
       "placeholder": "​",
       "style": "IPY_MODEL_8637c35f584e475a87717d5a63013569",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "7b1711500bef40cf9ae2b07d8c2e3542": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7cf3fa188ec04186a9b228c9e2920cce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f8c8df9c34944aee94c63bb8b1d55e83",
        "IPY_MODEL_091652d97c0d4a93b5b1fe0106c91387",
        "IPY_MODEL_55d66701dbac420a9b2ec7af6fb146b5"
       ],
       "layout": "IPY_MODEL_4f1a2e47f5f54eed8075dd7b79891139",
       "tabbable": null,
       "tooltip": null
      }
     },
     "83f2b8cce716409fb9377c9befc2ea17": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8416efc090a14e9880eaa0c4e84019dc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8637c35f584e475a87717d5a63013569": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8829d78ed7f74fd9b9e2ec75cf982aa5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8e1b8ed3f0ba455182bab1301771b94a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5a5fcbd627dd43ab85eb551ec677e65c",
       "placeholder": "​",
       "style": "IPY_MODEL_c27e815a90ed4cbb944de9dd7ab51848",
       "tabbable": null,
       "tooltip": null,
       "value": "generation_config.json: 100%"
      }
     },
     "921316d72748434c93fcd38aa9985644": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "96c89900b05f4f4f9d24d223bb9d64e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "970a0c6fbc544fae85787c02c3d45813": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cad1cbce58034d0090263797be3ec30a",
        "IPY_MODEL_5b33fd0b9fa04e0eb510ed453349dfdf",
        "IPY_MODEL_3cfbf61293fe4285a30c01c613458d6e"
       ],
       "layout": "IPY_MODEL_182404b9b77c4b16b20556950b1cc079",
       "tabbable": null,
       "tooltip": null
      }
     },
     "980db4513606422697a5388bb87cc600": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9ade8b63975240cbab64381d449bbb17": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9cef60211e3146b98d63a5440bc4e68c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ec8c6635fa7949a3b8172ad2b133d434",
       "placeholder": "​",
       "style": "IPY_MODEL_921316d72748434c93fcd38aa9985644",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.json: 100%"
      }
     },
     "a4e9ff98f7c44216852da5fa49603fa1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_575906c9f4554223b9ea9f120a653c58",
       "placeholder": "​",
       "style": "IPY_MODEL_64b70dee2765448cac3d0673489a2d05",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "a7811d4e7a9a4d3db7a8880eb4eccdfb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b568ed39be71443a82545a875a2a2d86",
       "placeholder": "​",
       "style": "IPY_MODEL_e5136f8a07914ccca28579a690dbb34a",
       "tabbable": null,
       "tooltip": null,
       "value": " 822/822 [00:00&lt;00:00, 99.4kB/s]"
      }
     },
     "aa51b39d46174140b9603faaabba2d4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "abe1bebc0a4d4fc6b7c353a8e97ebf5a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "adbb5cac139d4319a2bbae476f9152be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_320e0e0db48e48cba14a1f0f1a1a3969",
        "IPY_MODEL_0fb72b98c14446688ebfdeaf27d07a6a",
        "IPY_MODEL_dfb9dd78ef634506b8fb0750c1c4b8ac"
       ],
       "layout": "IPY_MODEL_e159f903fc5144489bad2f12ff5856ad",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ae646d4402db4b9485582aed8959661e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b0da95f331134fc8933ccc576a833cf3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b0f3955c9ce94007838874e46cc4e6f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b4181e1b18b347ba825d6594042b9f6d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b568ed39be71443a82545a875a2a2d86": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b72781192b914852beea6f2809ffe377": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bf038a1b264f4b309f4aa9a08f31e60e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6953d0ddb200413e8f54b6922db30837",
        "IPY_MODEL_421e580d500b4c4b9cffac45dd78aed0",
        "IPY_MODEL_a7811d4e7a9a4d3db7a8880eb4eccdfb"
       ],
       "layout": "IPY_MODEL_0cf5c093544647668f8f1b015bb92b2e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c27e815a90ed4cbb944de9dd7ab51848": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c7c81a507c4649019133aca2bf4bda14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b4181e1b18b347ba825d6594042b9f6d",
       "placeholder": "​",
       "style": "IPY_MODEL_ccfcff9c2acf47b79e994660fbac93f9",
       "tabbable": null,
       "tooltip": null,
       "value": " 247/247 [00:00&lt;00:00, 32.2kB/s]"
      }
     },
     "cad1cbce58034d0090263797be3ec30a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_391a8efb3bdd4a45a5161c1e659d2e85",
       "placeholder": "​",
       "style": "IPY_MODEL_b72781192b914852beea6f2809ffe377",
       "tabbable": null,
       "tooltip": null,
       "value": "added_tokens.json: 100%"
      }
     },
     "ccfcff9c2acf47b79e994660fbac93f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ce5a45ead78c46f98c12fa259f4cb13e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d50cba37e2544fa2aaa8def85301013b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d8291bd3bc59409ba56d7a8729eae912": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d9503f647b654943b4995dfa9f5320ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "da77bdb352f54cb99461e7604390f02c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "da85ba8cd9534d319c2851fc709c7ee8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "dfb9dd78ef634506b8fb0750c1c4b8ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4ce18d12636f43a9b6a6b93c8de3ebfd",
       "placeholder": "​",
       "style": "IPY_MODEL_d9503f647b654943b4995dfa9f5320ae",
       "tabbable": null,
       "tooltip": null,
       "value": " 8.41k/8.41k [00:00&lt;00:00, 960kB/s]"
      }
     },
     "e0c30bc790044174b035e11afe7e31d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e159f903fc5144489bad2f12ff5856ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e5136f8a07914ccca28579a690dbb34a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e8db43f175344ad4b18066819d0e12f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e90fc6722bee4b56a11ddba188ed2dbe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3dc5b9806c8c4f73adbad394ff2eea3f",
       "max": 1671853.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d8291bd3bc59409ba56d7a8729eae912",
       "tabbable": null,
       "tooltip": null,
       "value": 1671853.0
      }
     },
     "eb27f72c07eb4ac0865cd4564274c5dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_51f32d1bef96489e9cd08db935834ce0",
        "IPY_MODEL_e90fc6722bee4b56a11ddba188ed2dbe",
        "IPY_MODEL_5829beccb04c4847aee70f4095b41f9c"
       ],
       "layout": "IPY_MODEL_8829d78ed7f74fd9b9e2ec75cf982aa5",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ec8c6635fa7949a3b8172ad2b133d434": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ef10ad8ac56a4a39be82de5b4975a865": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f342f38b2900477e86666ed4bf20c661": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_83f2b8cce716409fb9377c9befc2ea17",
       "max": 1102312832.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_da77bdb352f54cb99461e7604390f02c",
       "tabbable": null,
       "tooltip": null,
       "value": 1102312832.0
      }
     },
     "f456daa7ef9c4752915505c77ef7d1d6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f5ca1f0ce9894b539ffdd7104e1c8b64": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f65a0f2866f4443fb4a34c96d6d9308d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f8c8df9c34944aee94c63bb8b1d55e83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8416efc090a14e9880eaa0c4e84019dc",
       "placeholder": "​",
       "style": "IPY_MODEL_ce5a45ead78c46f98c12fa259f4cb13e",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
